{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "354e74d1-f8c1-413f-bbed-aff507774112",
   "metadata": {},
   "source": [
    "<center> <span style=\"color:indigo\">Machine Learning e Inferencia Bayesiana</span> </center> \n",
    "\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5e/Logo-cucea.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "</center>\n",
    "    \n",
    "<center> <span style=\"color:DarkBlue\">  Tema 4: Probabilidad, Naive Bayes, datos ficticios de emails </span>  </center>\n",
    "<center> <span style=\"color:Blue\"> M. en C. Iván A. Toledano Juárez </span>  </center>\n",
    "\n",
    "## Clasificación de Correos SPAM usando Machine Learning\n",
    "\n",
    "Este ejercicio forma parte de las **notas del curso de *Machine Learning e Inferencia Bayesiana***. Trabajaremos un caso clásico de **clasificación binaria**: la detección de mensajes **SPAM** en una bandeja de entrada ficticia.\n",
    "\n",
    "Utilizaremos un conjunto de datos *simulado* que contiene ejemplos de correos electrónicos, donde cada uno está etiquetado como **SPAM** o **NO SPAM**. Un ejemplo de mensaje típico es:\n",
    "\n",
    "> *\"Congratulations, you won free gift!\"*\n",
    "\n",
    "Este tipo de mensaje contiene palabras clave como `\"congratulations\"`, `\"won\"`, `\"free\"` y `\"gift\"`, frecuentemente asociadas al correo no deseado.\n",
    "\n",
    "---\n",
    "\n",
    "En este notebook realizaremos el análisis en dos enfoques complementarios:\n",
    "\n",
    "- **Implementación manual del modelo Naive Bayes**, paso a paso, para comprender a profundidad los fundamentos teóricos y probabilísticos.\n",
    "- **Uso de Scikit-learn** para validar el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d0f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4563e42e-7f77-43af-a25e-289e1561d296",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e2cc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congratulations</th>\n",
       "      <th>you</th>\n",
       "      <th>won</th>\n",
       "      <th>free</th>\n",
       "      <th>gift</th>\n",
       "      <th>attached</th>\n",
       "      <th>sincerely</th>\n",
       "      <th>thanks</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   congratulations  you  won  free  gift  attached  sincerely  thanks  spam\n",
       "0                1    1    0     1     0         0          1       0     1\n",
       "1                1    1    1     1     0         0          0       1     1\n",
       "2                1    1    1     1     1         1          1       0     1\n",
       "3                1    0    1     1     1         0          0       1     1\n",
       "4                1    0    1     1     1         0          0       1     1\n",
       "5                0    0    1     1     1         0          1       0     1\n",
       "6                0    1    0     1     0         1          0       1     0\n",
       "7                0    1    0     0     1         1          0       1     0\n",
       "8                0    0    0     0     0         1          1       0     0\n",
       "9                1    0    1     0     0         0          1       0     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam = pd.read_csv('../data/spam/spam_ficticio.csv')\n",
    "df_spam.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0198da1-0a92-43f5-8238-6c6a1f0d3b19",
   "metadata": {},
   "source": [
    "### Implementación manual del clasificador Naive Bayes\n",
    "\n",
    "A continuación, se presenta una función personalizada (`nb_casero`) que implementa desde cero el algoritmo **Naive Bayes multivariado binario**. Esta función sirve como ejemplo claro de cómo se aplica el **teorema de Bayes** para calcular las probabilidades posteriores para cada clase, bajo el supuesto de independencia condicional entre las variables predictoras.\n",
    "\n",
    "La función trabaja de la siguiente manera:\n",
    "\n",
    "- Se calcula la **tabla de probabilidades condicionales** $P(x_i = 1 \\mid y)$ para cada variable binaria `x_i` y clase `y`, utilizando los datos de entrenamiento.\n",
    "- Se aplican las fórmulas:\n",
    "  \n",
    "  \\begin{equation}\n",
    "  P(y=1 \\mid \\mathbf{x}) \\propto P(y=1) \\cdot \\prod_i P(x_i \\mid y=1)\n",
    "  \\end{equation}\n",
    "  \\begin{equation}\n",
    "  P(y=0 \\mid \\mathbf{x}) \\propto P(y=0) \\cdot \\prod_i P(x_i \\mid y=0)\n",
    "  \\end{equation}\n",
    "  \n",
    "- Para cada observación en el conjunto de prueba, se calcula la probabilidad posterior para cada clase (sin normalizar) y se asigna la clase con mayor probabilidad.\n",
    "\n",
    "Además, para cada observación se imprime en consola el valor de las probabilidades condicionales calculadas (`p_0`, `p_1`) y la predicción final, permitiendo una comprensión detallada de cada paso.\n",
    "\n",
    "Esta implementación resalta de forma didáctica los siguientes conceptos clave:\n",
    "\n",
    "- Cálculo de la verosimilitud (*likelihood*) para variables binarias.\n",
    "- Aplicación del teorema de Bayes en clasificación.\n",
    "- Comparación entre las probabilidades para tomar la decisión final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d15268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función custom para hacer la clasificación en base al teorema de Bayes\n",
    "def nb_casero(df_train,df_test,features,target):\n",
    "    \n",
    "    # tabla de probabilidad(likelihood)\n",
    "    df_prob = df_train.groupby(target).mean()\n",
    "    \n",
    "    p_0_list = []\n",
    "    p_1_list = []\n",
    "    pred_list=[] # lista de predicciones\n",
    "\n",
    "    # Probabilidades totales del target\n",
    "    p_target_0 = df_train.groupby(target).size()[0]/df_train.shape[0]\n",
    "    p_target_1 = df_train.groupby(target).size()[1]/df_train.shape[0]\n",
    "\n",
    "    # iteramos sobre todos los registros(filas) utilizando método iterrows()\n",
    "    for index, row in df_test.iterrows():\n",
    "        \n",
    "        p_0 = p_target_0 # inicializamos la probabilidad condicional total\n",
    "        p_1 = p_target_1 # inicializamos la probabilidad condicional total\n",
    "\n",
    "        #iteracion sobre las variables\n",
    "        for var in features:\n",
    "            if row[var]==1: # caso var=1\n",
    "                p_0 *= df_prob[var].loc[0] # se multiplica por su respectiva entrada en la tabla de prob.\n",
    "                p_1 *= df_prob[var].loc[1]\n",
    "            elif row[var]==0: # caso var=0\n",
    "                p_0 *= 1.0-df_prob[var].loc[0] # se multiplica por su respectivo complemento en la tabla de prob.\n",
    "                p_1 *= 1.0-df_prob[var].loc[1]\n",
    "        \n",
    "        p_0_list.append(p_0)\n",
    "        p_1_list.append(p_1)\n",
    "        pred = np.where(p_1>p_0,1,0) # Se comparan las dos prob condicionales, se elige la etiqueta de la mayor\n",
    "        pred_list.append(int(pred)) # Se agrega a la lista de predicciones\n",
    "        print('p_0=',round(p_0,5),'p_1=',round(p_1,5),'pred=',int(pred))\n",
    "        \n",
    "    return p_0_list, p_1_list, pred_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e487e3-a4d0-4933-af4c-f1e782f150eb",
   "metadata": {},
   "source": [
    "### Implementación de la función casera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e56bf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_0= 5e-05 p_1= 0.02894 pred= 1\n"
     ]
    }
   ],
   "source": [
    "# Dataframe de entrenamiento\n",
    "df_train = pd.read_csv('../data/spam/spam_ficticio.csv')\n",
    "\n",
    "# Lista de variables de entrada y objetivo\n",
    "target = 'spam'\n",
    "features = df_train.columns.drop(target)\n",
    "\n",
    "# Dataframe de prueba\n",
    "df_test = pd.DataFrame(data={},\n",
    "                       columns=features)\n",
    "# Añadimos un renglón al set de validacion\n",
    "df_test.loc[len(df_test.index)] = [1,1,1,1,1,0,0,0] # codificacion de mensaje \"congratulations, you won free gift\"\n",
    "\n",
    "p_0_list, p_1_list, pred_list = nb_casero(df_train=df_train,\n",
    "                                          df_test=df_test,\n",
    "                                          features=features,\n",
    "                                          target=target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
